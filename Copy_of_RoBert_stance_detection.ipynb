{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AoMR-4NUILJ",
        "outputId": "a5f69a0a-9cf9-44e3-da09-3dde863d1adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS0-GsWMFgwa",
        "outputId": "7c746115-18ad-4b4c-b89b-22dd0a52a7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbPcMAUEFtIU",
        "outputId": "46d4840a-9ba6-46ed-c8ac-1fb9b4cd0bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModel #,AutoModelForSequenceClassification\n",
        "\n",
        "modelName = \"roberta-base\"\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(modelName)\n",
        "model = AutoModel.from_pretrained(\n",
        "    modelName,\n",
        "    num_labels=3,\n",
        "    )\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZzZ6sZjF6iA"
      },
      "outputs": [],
      "source": [
        "#example working of tokenizer\n",
        "tokens = tokenizer.tokenize(\"Hello bert model stance\",\"Hello apple\")\n",
        "tokenIds = tokenizer.convert_tokens_to_ids(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hy5VOaB8KBM",
        "outputId": "3923d96b-0dcd-4de0-a248-a249f28b4a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'Ġb', 'ert', 'Ġmodel', 'Ġstance', 'Hello', 'Ġapple']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHHPxdSwoCK_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ufGl0lOhoF75",
        "outputId": "659a7c49-6ec0-4003-c22b-3d334047dc45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Body ID                                        articleBody  \\\n",
              "7025        3004      176  Hunky mensch who took down violent bully looks...   \n",
              "3652       22555     1303  Description: Fake news / Satire\\nCirculating s...   \n",
              "7995       21044     1245  YouTuber Josh Paler Lin is normally a prankste...   \n",
              "9383        3274      195  A video posted by ISIL terrorists in Iraq purp...   \n",
              "2368        9744      592  Warning: graphic image below\\n\\nA 22-year-old ...   \n",
              "4805       40554     2130  Vice founder Shane Smith, with something that ...   \n",
              "9639        7134      444  Hospital authorities are carrying out an inves...   \n",
              "7954       31024     1728  A Twitter account associating itself with Fox ...   \n",
              "7090       27458     1545  Macaulay Culkin has once again died — at least...   \n",
              "1289       28812     1610  Ahmed Abdi Godane — the leader of al Shabab, t...   \n",
              "\n",
              "                                               Headline  Stance  \n",
              "7025  'Banksy' Reacts To Paris Attack With Poignant ...       2  \n",
              "3652  L. Jinny? Abdel-Majed Abdel Bary, UK Rapper, S...       2  \n",
              "7995  Eyewitness Says Viral Video of Homeless Man Wa...       0  \n",
              "9383  Attorney: New audio reveals pause in gunfire w...       2  \n",
              "2368  Report: Taliban Detainee Swapped for Bowe Berg...       2  \n",
              "4805  Obama: murder of James Foley 'shocks the consc...       2  \n",
              "9639  Rumor: Gold Apple Watch Edition priced up to $...       2  \n",
              "7954  The @FoxNewsPress Account Tweeting Lawsuit Thr...       1  \n",
              "7090             Apple 'working on 12-inch MacBook Air'       2  \n",
              "1289  Pentagon: Airstrike killed terror leader in So...       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6421f72-2c31-412c-9713-926df425485f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7025</th>\n",
              "      <td>3004</td>\n",
              "      <td>176</td>\n",
              "      <td>Hunky mensch who took down violent bully looks...</td>\n",
              "      <td>'Banksy' Reacts To Paris Attack With Poignant ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3652</th>\n",
              "      <td>22555</td>\n",
              "      <td>1303</td>\n",
              "      <td>Description: Fake news / Satire\\nCirculating s...</td>\n",
              "      <td>L. Jinny? Abdel-Majed Abdel Bary, UK Rapper, S...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>21044</td>\n",
              "      <td>1245</td>\n",
              "      <td>YouTuber Josh Paler Lin is normally a prankste...</td>\n",
              "      <td>Eyewitness Says Viral Video of Homeless Man Wa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9383</th>\n",
              "      <td>3274</td>\n",
              "      <td>195</td>\n",
              "      <td>A video posted by ISIL terrorists in Iraq purp...</td>\n",
              "      <td>Attorney: New audio reveals pause in gunfire w...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2368</th>\n",
              "      <td>9744</td>\n",
              "      <td>592</td>\n",
              "      <td>Warning: graphic image below\\n\\nA 22-year-old ...</td>\n",
              "      <td>Report: Taliban Detainee Swapped for Bowe Berg...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4805</th>\n",
              "      <td>40554</td>\n",
              "      <td>2130</td>\n",
              "      <td>Vice founder Shane Smith, with something that ...</td>\n",
              "      <td>Obama: murder of James Foley 'shocks the consc...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9639</th>\n",
              "      <td>7134</td>\n",
              "      <td>444</td>\n",
              "      <td>Hospital authorities are carrying out an inves...</td>\n",
              "      <td>Rumor: Gold Apple Watch Edition priced up to $...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7954</th>\n",
              "      <td>31024</td>\n",
              "      <td>1728</td>\n",
              "      <td>A Twitter account associating itself with Fox ...</td>\n",
              "      <td>The @FoxNewsPress Account Tweeting Lawsuit Thr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7090</th>\n",
              "      <td>27458</td>\n",
              "      <td>1545</td>\n",
              "      <td>Macaulay Culkin has once again died — at least...</td>\n",
              "      <td>Apple 'working on 12-inch MacBook Air'</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1289</th>\n",
              "      <td>28812</td>\n",
              "      <td>1610</td>\n",
              "      <td>Ahmed Abdi Godane — the leader of al Shabab, t...</td>\n",
              "      <td>Pentagon: Airstrike killed terror leader in So...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6421f72-2c31-412c-9713-926df425485f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6421f72-2c31-412c-9713-926df425485f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6421f72-2c31-412c-9713-926df425485f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df = pd.read_csv('./stance_all_1_4.csv')\n",
        "df = df.sample(frac = 1)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a22Ab-splMfu",
        "outputId": "57c21f2b-a739-4fed-ce2b-088355f69e10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df['Stance'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gELgO-iHPLmm",
        "outputId": "a45a1963-474e-4b9b-82fb-7219343e31bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txgsvPRU5rqf"
      },
      "outputs": [],
      "source": [
        "articleBodies = df.articleBody.values\n",
        "headlines = df.Headline.values\n",
        "stances = df.Stance.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d54utDD257LY",
        "outputId": "ed8f81fe-51ba-47c5-ae21-a88daa020205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headline:  'Banksy' Reacts To Paris Attack With Poignant Drawing\n",
            "Article Body:  Hunky mensch who took down violent bully looks like Paul Rudd, is not Paul Rudd\n",
            "\n",
            "Sorry, amateur celebrity sleuths — the actor Paul Rudd was not involved in the tackling of a man shouting homophobic slurs in a Dallas airport last week.\n",
            "\n",
            "A man who looked almost exactly like the This Is 40 star was caught on video helping to tackle a man who yelled homophobic slurs and kicked another man waiting in Dallas-Fort Worth International Airport last week.\n",
            "\n",
            "After the man became violent, a group of people swarmed him and brought him to the ground, with the help of a wavy-haired hunk in a checkered shirt who looks a lot like Paul Rudd. The video of the incident quickly went viral, amid rumors that the Hollywood funnyman was involved.\n",
            "\n",
            "But Paul Rudd’s rep confirmed to TIME on Monday afternoon that the man with a noble heart, quick reflexes, and a strong sense of social outrage is not Paul Rudd.\n",
            "\n",
            "Ladies: That means there is a mensch out there who looks like Paul Rudd but isn’t Paul Rudd, and also appears to be nice, hunky, and quick to stand up to injustice.\n",
            "Token IDs: tensor([    0,   108,   387, 10950,   219,   108,  1223, 19170,   598,  2201,\n",
            "        23800,   590,  6002, 35090, 34977,     2,     2, 38831,  4122,   475,\n",
            "         1290,   611,    54,   362,   159,  4153, 23934,  1326,   101,  1206,\n",
            "        22114,     6,    16,    45,  1206, 22114, 50118, 50118, 31535,     6,\n",
            "        13836,  6794, 18388,  5914,    29,    93,     5,  2701,  1206, 22114,\n",
            "           21,    45,   963,    11,     5, 12985,     9,    10,   313, 14487,\n",
            "        29062, 31484,    11,    10,  3160,  3062,    94,   186,     4, 50118,\n",
            "        50118,   250,   313,    54,  1415,   818,  2230,   101,     5,   152,\n",
            "         1534,   843,   999,    21,  2037,    15,   569,  1903,     7,  3692,\n",
            "           10,   313,    54, 19475, 29062, 31484,     8,  5836,   277,   313,\n",
            "         2445,    11,  3160,    12, 23565, 13399,  1016,  4414,    94,   186,\n",
            "            4, 50118, 50118,  4993,     5,   313,  1059,  4153,     6,    10,\n",
            "          333,     9,    82,  3514, 17651,   123,     8,  1146,   123,     7,\n",
            "            5,  1255,     6,    19,     5,   244,     9,    10,   885, 19909,\n",
            "           12, 29542,  1368,  6435,    11,    10,  5851,   438, 20093,  6399,\n",
            "           54,  1326,    10,   319,   101,  1206, 22114,     4,    20,   569,\n",
            "            9,     5,  1160,  1335,   439,  7696,     6,  2876,  8762,    14,\n",
            "            5,  3049,  6269,   397,    21,   963,     4, 50118, 50118,  1708,\n",
            "         1206, 22114,    17,    27,    29,  2851,  1474,     7, 18034,    15,\n",
            "          302,  1390,    14,     5,   313,    19,    10, 25097,  1144,     6,\n",
            "         2119, 32229,   293,     6,     8,    10,   670,  1472,     9,   592,\n",
            "        10618,    16,    45,  1206, 22114,     4, 50118, 50118,   574, 40979,\n",
            "           35,   280,   839,    89,    16,    10,   475,  1290,   611,    66,\n",
            "           89,    54,  1326,   101,  1206, 22114,    53,   965,    17,    27,\n",
            "           90,  1206, 22114,     6,     8,    67,  2092,     7,    28,  2579,\n",
            "            6, 26458,  4122,     6,     8,     2])\n"
          ]
        }
      ],
      "source": [
        "input_ids=[]\n",
        "attention_masks=[]\n",
        "\n",
        "for i in range(len(headlines)): \n",
        "  encoded_dict=tokenizer.encode_plus(\n",
        "      [headlines[i],articleBodies[i]], #sentence to encode\n",
        "      add_special_tokens=True, #add special characters\n",
        "      max_length=256,\n",
        "      truncation=True, #add max len and truncate the sentence\n",
        "      # padding = 'max_length'\n",
        "      pad_to_max_length=True, \n",
        "      return_attention_mask=True,#construct attention mask\n",
        "      return_tensors='pt' #return pytorch tensor\n",
        "  )\n",
        "  #add encoded sentence to the list\n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  # And its attention mask (simply differentiates padding from non-padding).\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "stances = torch.tensor(stances)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Headline: ', headlines[0])\n",
        "print('Article Body: ',articleBodies[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me7Z90XH57Ak"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, stances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIFMUsm29Y5c"
      },
      "outputs": [],
      "source": [
        "# 0.7 - training and 0.3- testing\n",
        "train_size = int(0.7*len(dataset))\n",
        "test_size = len(dataset)-train_size\n",
        "\n",
        "# splitting \n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9WE3Mz19Y0J"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,sampler = RandomSampler(train_dataset),batch_size = 16)\n",
        "test_dataloader = DataLoader(test_dataset,sampler = RandomSampler(test_dataset),batch_size = 16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxxjmf8BNi1k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6gg2Z-pX6p5",
        "outputId": "70ea713c-4cac-4452-cecb-b17103a40fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[    0, 37589, 16371,  ...,  3533,    21,     2],\n",
            "        [    0,  5532,  3091,  ..., 50118,   133,     2],\n",
            "        [    0, 37142,    18,  ..., 10652, 17918,     2],\n",
            "        ...,\n",
            "        [    0, 34052,   611,  ...,    49,  1420,     2],\n",
            "        [    0,   104, 20115,  ...,  9072,    41,     2],\n",
            "        [    0,  7629,    29,  ..., 14631,  1464,     2]]), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]), tensor([2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2])]\n"
          ]
        }
      ],
      "source": [
        "itr = iter(train_dataloader)\n",
        "data = itr.next()\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIdRIzJcW8jw",
        "outputId": "89d343df-5b01-4a3b-87c3-0a1e69fbdf30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# optimizer \n",
        "from transformers import AdamW\n",
        "optimizer=AdamW(model.parameters(),lr=5e-5,eps=1e-8)\n",
        "epochs=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3icIlOZ9k9x"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm405Qnb-sHv",
        "outputId": "9febd542-bf5a-4193-9f49-63473f78899b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))\n",
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFkIy1sTCH4k",
        "outputId": "5910091c-6a94-45e3-8260-4034c4c5b815"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    8863\n",
              "1     914\n",
              "0     223\n",
              "Name: Stance, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.Stance.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNpn85W7hnb9",
        "outputId": "44c1707e-410c-4f67-a941-fe5684ea18d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "438"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "8kyOc_k0EGw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = torch.nn.Linear(model.config.hidden_size, 1)\n",
        "loss_func = nn.BCEWithLogitsLoss(reduction='mean')"
      ],
      "metadata": {
        "id": "5REcX6D7Fnam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "HkEzIYtJ-sEp",
        "outputId": "c204ebcd-41c6-459b-afb8-0b6460c02a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "epoch = 0 step = 0 tensor([[ 9.5538e-02],\n",
            "        [ 4.1897e-01],\n",
            "        [-1.0487e-03],\n",
            "        [ 2.4889e-02],\n",
            "        [ 1.1356e-01],\n",
            "        [-3.5705e-01],\n",
            "        [-3.1098e-04],\n",
            "        [ 1.5651e-02],\n",
            "        [ 2.5249e-02],\n",
            "        [ 1.7481e-01],\n",
            "        [-4.0313e-01],\n",
            "        [ 1.6982e-01],\n",
            "        [-1.9781e-02],\n",
            "        [-1.1296e-01],\n",
            "        [ 3.3837e-02],\n",
            "        [-3.7252e-02]], grad_fn=<AddmmBackward0>)\n",
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4056be0e11f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3145\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ],
      "source": [
        "for epoch_i in range(0,epochs):\n",
        "  model.train()\n",
        "  print(epoch_i)\n",
        "  # print(len(train_dataloader))\n",
        "  epoch_loss = 0\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    if step>2:\n",
        "      break\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    # print(b_labels)\n",
        "    print(\"epoch =\",epoch_i,\"step =\",step,end=\" \")\n",
        "    model.zero_grad() \n",
        "    output = model(input_ids=b_input_ids, \n",
        "                             attention_mask=b_input_mask, \n",
        "                            #  labels=b_labels\n",
        "                   )\n",
        "    pooled_output = torch.mean(output.last_hidden_state, 1)\n",
        "    # final logits\n",
        "    pooled_output = nn.Dropout()(pooled_output)\n",
        "    pooled_output = torch.nn.Linear(model.config.hidden_size, model.config.hidden_size)(pooled_output)\n",
        "    pooled_output = F.relu(pooled_output)\n",
        "    pooled_output = nn.Dropout()(pooled_output)\n",
        "    logits = classifier(pooled_output)\n",
        "    print(logits)\n",
        "    expected = []\n",
        "    for i in range(len(logits[0])):\n",
        "      expected.append(logits[0][i])\n",
        "    print(type(b_labels))\n",
        "    # calculate loss\n",
        "    loss = loss_func(expected, b_labels)\n",
        "    print(\"loss =\",loss)\n",
        "    epoch_loss += loss\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"Total loss in epoch =\",epoch_loss)\n",
        "  print(\"avg loss in epoch\",epoch_i,\" =\",epoch_loss/len(train_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S4sZZvoUNYB"
      },
      "outputs": [],
      "source": [
        "model_save_name=\"bert-stance-model.pt\"\n",
        "path = f'/content/gdrive/My Drive/{model_save_name}'\n",
        "torch.save(model.state_dict(),path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBgMomTUJNjx"
      },
      "outputs": [],
      "source": [
        "save_directory = 'saved'\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUhzEt20FB6t"
      },
      "outputs": [],
      "source": [
        "#Define a helper function for calculating accuracy.\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def validation_accuracy(orig, pred):\n",
        "  correct = 0\n",
        "  agree_correct=0\n",
        "  disagree_correct=0\n",
        "  unrelated_correct=0\n",
        "  total_agree=0\n",
        "  total_disagree=0\n",
        "  total_unrelated=0\n",
        "  for i in range(len(orig)):\n",
        "    if orig[i]==pred[i]:\n",
        "      correct+=1\n",
        "    if orig[i]==1:\n",
        "      total_agree+=1\n",
        "      if pred[i]==1:\n",
        "        agree_correct+=1\n",
        "    if orig[i]==0:\n",
        "      total_disagree+=1\n",
        "      if pred[i]==0:\n",
        "        disagree_correct+=1 \n",
        "    if orig[i]==2:\n",
        "      total_unrelated+=1\n",
        "      if pred[i]==2:\n",
        "        unrelated_correct+=1\n",
        "\n",
        "  if total_agree==0:\n",
        "    agree_acc = 1\n",
        "  else:\n",
        "    agree_acc = agree_correct/total_agree\n",
        "\n",
        "  if total_disagree==0:\n",
        "    disagree_acc=1\n",
        "  else:\n",
        "    disagree_acc = disagree_correct/total_disagree\n",
        "\n",
        "  if total_unrelated==0:\n",
        "    unrelated_acc=1\n",
        "  else:\n",
        "    unrelated_acc = unrelated_correct/total_unrelated\n",
        "  return [correct/len(orig),agree_acc,disagree_acc,total_agree,total_disagree,unrelated_acc,total_unrelated]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM9sDaKIFPul"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p10RsMaA7Il"
      },
      "outputs": [],
      "source": [
        "## validation ##\n",
        "\n",
        "import torch.nn.functional as F\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_agree_accuracy=0\n",
        "total_disagree_accuracy=0\n",
        "total_unrelated_accuracy=0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "total_agree=0\n",
        "total_disagree=0\n",
        "total_unrelated=0\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for step,batch in enumerate(test_dataloader):\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    with torch.no_grad():        \n",
        "\n",
        "        print('step =',step)\n",
        "        output = model(b_input_ids, \n",
        "                                # token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        predictions = F.softmax(output.logits,dim=1)\n",
        "        labels = torch.argmax(predictions,dim=1)\n",
        "        print(\"original labels =\",b_labels )\n",
        "        print(\"labels =\",labels)\n",
        "\n",
        "    acc = validation_accuracy(b_labels, labels)\n",
        "    print(\"Accuracy for batch\",step+1,\" =\",acc[0])\n",
        "    total_eval_accuracy += acc[0]\n",
        "    total_agree_accuracy += acc[1]\n",
        "    total_disagree_accuracy+=acc[2]\n",
        "    total_agree+=acc[3]\n",
        "    total_disagree+=acc[4]\n",
        "    total_unrelated_accuracy+=acc[5]\n",
        "    total_unrelated+=acc[6]\n",
        "\n",
        "    # Accumulate the validation loss.\n",
        "    l=output.loss.item()\n",
        "    print(\"loss =\",l)\n",
        "    total_eval_loss += l\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = output.logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "\n",
        "# Report the final agree accuracy for this validation run.\n",
        "avg_agree_accuracy = total_agree_accuracy / total_agree\n",
        "print(\"Average Agree Accuracy: {0:.2f}\".format(avg_agree_accuracy))\n",
        "\n",
        "# Report the final disagree accuracy for this validation run.\n",
        "avg_disagree_accuracy = total_disagree_accuracy / total_disagree\n",
        "print(\"Average Disagree Accuracy: {0:.2f}\".format(avg_disagree_accuracy))\n",
        "\n",
        "# Report the final unrelated accuracy for this validation run.\n",
        "avg_unrelated_accuracy = total_unrelated_accuracy / total_unrelated\n",
        "print(\"Average Unrelated Accuracy: {0:.2f}\".format(avg_unrelated_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "print(\"Average validation loss =\",avg_val_loss)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "print(\"Validation took: {:}\".format(validation_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWLjKUacJuHI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}